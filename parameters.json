{
    "adam_beta_1": 0.9,
    "adam_beta_2": 0.98,
    "adam_epsilon": 1e-9,
    "batch_size": 32,
    "d_model": 512,
    "dff": 2048,
    "dropout": 0.1,
    "epoch": 1,
    "ln_epsilon": 1e-6,
    "max_len_c": 100,
    "max_len_p": 100,
    "num_head": 8,
    "num_layer": 12,
    "vocab_size_c": 1000,
    "vocab_size_p": 1000,
    "warmup_finetune": 200000,
    "warmup_pretrain": 10000,
    "word_len_c": 2,
    "word_len_p": 20
}